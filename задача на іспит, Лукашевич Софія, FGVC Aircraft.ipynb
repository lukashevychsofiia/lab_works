{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f76eff9b",
   "metadata": {},
   "source": [
    "Треба побудувати мережу для класифікації зображень з датасету FGVC Aircraft (https://pytorch.org/vision/stable/generated/torchvision.datasets.FGVCAircraft.html#torchvision.datasets.FGVCAircraft)\n",
    "\n",
    "Завантажимо папку fgvc-aircraft-2013b звідси:\n",
    "https://www.kaggle.com/datasets/seryouxblaster764/fgvc-aircraft?select=fgvc-aircraft-2013b\n",
    "\n",
    "В описі датасету (https://www.robots.ox.ac.uk/~vgg/data/fgvc-aircraft/) зазначено, що дані вже розбиті на однакові тренувальну, валідаційну та тестову частини.\n",
    "\n",
    "Як tagret variable оберемо manufacturer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "44a9dd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8339fa0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a4c5d7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "ba2886af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "67eeed7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969047bf",
   "metadata": {},
   "source": [
    "Завантажимо txt файли"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bea14465",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = {\n",
    "    \"test\": \"/Users/sofiialukashevych/Desktop/exam data aircraft/fgvc-aircraft-2013b/data/images_manufacturer_test.txt\",\n",
    "    \"train\": \"/Users/sofiialukashevych/Desktop/exam data aircraft/fgvc-aircraft-2013b/data/images_manufacturer_train.txt\",\n",
    "    \"val\": \"/Users/sofiialukashevych/Desktop/exam data aircraft/fgvc-aircraft-2013b/data/images_manufacturer_val.txt\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "92f46c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#класс для свтворення датасету\n",
    "class AircraftDataset(Dataset):\n",
    "    def __init__(self, txt_file, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        with open(txt_file, 'r') as file:\n",
    "            self.image_labels = [self._split_line(line.strip()) for line in file.readlines()]\n",
    "\n",
    "    def _split_line(self, line):\n",
    "        parts = line.split(maxsplit=1)\n",
    "        if len(parts) != 2:\n",
    "            raise ValueError(f\"Line '{line}' is not in the expected format.\")\n",
    "        return parts\n",
    "    def __len__(self):\n",
    "        return len(self.image_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.root_dir, self.image_labels[idx][0] + '.jpg')\n",
    "        image = Image.open(img_name)\n",
    "        label = self.image_labels[idx][1]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "178ca815",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AircraftDatasetWithEncoding(AircraftDataset):\n",
    "    def __init__(self, txt_file, root_dir, transform=None):\n",
    "        super().__init__(txt_file, root_dir, transform)\n",
    "        # Extract all labels\n",
    "        all_labels = []\n",
    "        for item in self.image_labels:\n",
    "            if len(item) != 2:\n",
    "                raise ValueError(f\"Line '{' '.join(item)}' in file {txt_file} is not in the expected format.\")\n",
    "            all_labels.append(item[1])\n",
    "        # Initialize and fit label encoder\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        self.label_encoder.fit(all_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name, label = self.image_labels[idx]\n",
    "        image = Image.open(os.path.join(self.root_dir, img_name + '.jpg'))\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        # Encode label\n",
    "        encoded_label = self.label_encoder.transform([label])[0]\n",
    "        encoded_label_tensor = torch.tensor(encoded_label, dtype=torch.long)\n",
    "\n",
    "        return image, encoded_label_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8d429a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#трансформація картинок\n",
    "transform = transforms.Compose([\n",
    "    #ресайз для входу картинок у CNN\n",
    "    transforms.Resize((224, 224)),  \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c27ca5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#шляхи до файлів\n",
    "root_dir = '/Users/sofiialukashevych/Desktop/exam data aircraft/fgvc-aircraft-2013b/data/images'\n",
    "train_file = \"/Users/sofiialukashevych/Desktop/exam data aircraft/fgvc-aircraft-2013b/data/images_manufacturer_train.txt\"\n",
    "val_file = \"/Users/sofiialukashevych/Desktop/exam data aircraft/fgvc-aircraft-2013b/data/images_manufacturer_val.txt\"\n",
    "test_file = \"/Users/sofiialukashevych/Desktop/exam data aircraft/fgvc-aircraft-2013b/data/images_manufacturer_test.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d82177c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#створимо датасет\n",
    "train_dataset = AircraftDatasetWithEncoding(txt_file=train_file, root_dir=root_dir, transform=transform)\n",
    "val_dataset = AircraftDatasetWithEncoding(txt_file=val_file, root_dir=root_dir, transform=transform)\n",
    "test_dataset = AircraftDatasetWithEncoding(txt_file=test_file, root_dir=root_dir, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "6fe3c63d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-0.5082, -0.5082, -0.4911,  ...,  0.2282,  0.2282,  0.2282],\n",
       "          [-0.5253, -0.5082, -0.5082,  ...,  0.2282,  0.2111,  0.2282],\n",
       "          [-0.5253, -0.5082, -0.5082,  ...,  0.2282,  0.2111,  0.2111],\n",
       "          ...,\n",
       "          [-1.0219, -1.1418, -1.7069,  ..., -0.8335, -0.8335, -1.2617],\n",
       "          [-1.2274, -1.7240, -1.2617,  ..., -0.7479, -1.3302, -2.0665],\n",
       "          [-1.3473, -1.5185, -1.4672,  ..., -0.3883, -1.7069, -2.1179]],\n",
       " \n",
       "         [[-0.2675, -0.2675, -0.2675,  ...,  0.4853,  0.5028,  0.5028],\n",
       "          [-0.2675, -0.2675, -0.2850,  ...,  0.4853,  0.4853,  0.5028],\n",
       "          [-0.2500, -0.2850, -0.2850,  ...,  0.4678,  0.4853,  0.4853],\n",
       "          ...,\n",
       "          [-0.8803, -1.0203, -1.6155,  ..., -0.5476, -0.5126, -1.0728],\n",
       "          [-1.0553, -1.6155, -1.0903,  ..., -0.3550, -1.0203, -1.9832],\n",
       "          [-1.1604, -1.3354, -1.2829,  ...,  0.0476, -1.5280, -2.0357]],\n",
       " \n",
       "         [[ 0.3393,  0.3219,  0.3393,  ...,  0.9145,  0.9145,  0.9319],\n",
       "          [ 0.3393,  0.3393,  0.3568,  ...,  0.9319,  0.9145,  0.9319],\n",
       "          [ 0.3568,  0.3393,  0.3568,  ...,  0.9145,  0.9319,  0.9319],\n",
       "          ...,\n",
       "          [-0.6193, -0.7761, -1.3687,  ..., -0.2881, -0.2184, -0.8458],\n",
       "          [-0.7761, -1.3513, -0.7936,  ...,  0.0256, -0.6715, -1.7347],\n",
       "          [-0.8110, -1.0027, -0.9504,  ...,  0.4439, -1.2467, -1.7870]]]),\n",
       " tensor(4))"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#виведемо першу картинку та лейбл з тренувального датасету\n",
    "first_img, first_label = test_dataset[0]\n",
    "first_img, first_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4d38a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f298242",
   "metadata": {},
   "source": [
    "Далі перейдемо до написання нейронної мережі.\n",
    "Спочатку зробимо CNN з Dropout (regularization technique)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5eeb4edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CNN з Dropout\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "\n",
    "        #згорткові шари, витягуємо ознаки\n",
    "        self.features = nn.Sequential(\n",
    "            #перший згортковий шар з 64 фільтрами, розмір ядра 11x11 \n",
    "            #крок 4 для зменшення розмірності\n",
    "            #додавання 2 для крайніх пікселів\n",
    "            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
    "            #функція активації ReLU для нелінійності\n",
    "            nn.ReLU(inplace=True),  \n",
    "            #Maxpooling для зменшення просторових розмірів\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),  \n",
    "\n",
    "            #другий згортковий шар з 192 фільтрами, розмір ядра 5x5 \n",
    "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "\n",
    "            #третій згортковий шар з 384 фільтрами, розмір ядра 3x3\n",
    "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            #четвертий згортковий шар з 256 фільтрами, розмір ядра 3x3\n",
    "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            #п’ятий згортковий шар з 256 фільтрами, також розмір ядра 3x3\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            #MaxPooling для зменшення розміру перед класифікацією\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "        )\n",
    "\n",
    "        #AdaptiveAvgPooling\n",
    "         #зміна розміру карти ознак до 6x6\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((6, 6)) \n",
    "\n",
    "        #класифікація (повністʼю зʼєднані шари)\n",
    "        self.classifier = nn.Sequential(\n",
    "            #Dropout для зменшення перенавчання\n",
    "            nn.Dropout(), \n",
    "            #лінійний шар\n",
    "            nn.Linear(256 * 6 * 6, 4096), \n",
    "            #функція активації\n",
    "            nn.ReLU(inplace=True),  \n",
    "            #ще один шар Dropout для регуляризації\n",
    "            nn.Dropout(),  \n",
    "            #ще один лінійний шар\n",
    "            nn.Linear(4096, 4096),\n",
    "            #останній шар з виходами num_classes\n",
    "            nn.Linear(4096, num_classes),  \n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        #прохід через згорткові шари\n",
    "        x = self.features(x)  \n",
    "        #адаптивний пулінг\n",
    "        x = self.avgpool(x)\n",
    "         #вирівнювання виходу для лінійних шарів\n",
    "        x = torch.flatten(x, 1) \n",
    "        #прохід через лінійні шари\n",
    "        x = self.classifier(x)  \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "cc4f97c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 30 #стільки є виробників в файлі manufacturer.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "01183d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleCNN(num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "13ab80b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_loss_values = []\n",
    "step_loss_values = []\n",
    "#функція втрат\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "#оптимізатор Адам\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2744eb03",
   "metadata": {},
   "source": [
    "Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b7f5c9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "1200499e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data loader для тренувального датасету\n",
    "train_data_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "e56d2719",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_data_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "326790c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[[[-0.4739, -0.4739, -0.4568,  ..., -0.5424, -0.5424, -0.5424],\n",
      "          [-0.4739, -0.4739, -0.4568,  ..., -0.5596, -0.5596, -0.5596],\n",
      "          [-0.4739, -0.4739, -0.4568,  ..., -0.5424, -0.5424, -0.5424],\n",
      "          ...,\n",
      "          [-0.9705, -1.1760, -1.6727,  ..., -0.7479, -0.5596, -1.0048],\n",
      "          [-1.2617, -1.6384, -1.2274,  ..., -1.0048, -1.1418, -2.0494],\n",
      "          [-1.3815, -1.5185, -1.4500,  ..., -0.4911, -1.5185, -2.1179]],\n",
      "\n",
      "         [[-0.1275, -0.1450, -0.1275,  ..., -0.1099, -0.1099, -0.1099],\n",
      "          [-0.1450, -0.1275, -0.1275,  ..., -0.1275, -0.1275, -0.1275],\n",
      "          [-0.1275, -0.1275, -0.1275,  ..., -0.1275, -0.1275, -0.1099],\n",
      "          ...,\n",
      "          [-0.8277, -1.0203, -1.5455,  ..., -0.5301, -0.2850, -0.8627],\n",
      "          [-1.1078, -1.5280, -1.0553,  ..., -0.6702, -0.7927, -1.9482],\n",
      "          [-1.1604, -1.3354, -1.2479,  ..., -0.0924, -1.3004, -2.0182]],\n",
      "\n",
      "         [[ 0.3568,  0.3219,  0.3393,  ...,  0.3568,  0.3568,  0.3568],\n",
      "          [ 0.3393,  0.3393,  0.3393,  ...,  0.3393,  0.3393,  0.3393],\n",
      "          [ 0.3393,  0.3393,  0.3393,  ...,  0.3568,  0.3393,  0.3568],\n",
      "          ...,\n",
      "          [-0.5495, -0.7587, -1.2816,  ..., -0.2707,  0.0256, -0.6193],\n",
      "          [-0.8284, -1.2641, -0.7587,  ..., -0.3230, -0.4275, -1.6999],\n",
      "          [-0.8284, -1.0201, -0.9156,  ...,  0.3045, -0.9853, -1.7870]]],\n",
      "\n",
      "\n",
      "        [[[-1.4329, -1.5185, -1.5357,  ..., -0.8335, -0.7137, -0.5424],\n",
      "          [-1.4158, -1.4158, -1.5014,  ..., -1.2617, -1.1589, -1.0733],\n",
      "          [-1.4158, -1.3987, -1.5014,  ..., -1.4158, -1.3815, -1.2959],\n",
      "          ...,\n",
      "          [-1.0390, -1.2445, -1.6727,  ..., -1.1589, -0.9363, -1.1932],\n",
      "          [ 0.0569, -0.1999, -0.2684,  ..., -1.3473, -0.8678, -1.8953],\n",
      "          [-0.8335, -1.2445, -0.4397,  ..., -1.0733, -1.3302, -2.1008]],\n",
      "\n",
      "         [[-1.2129, -1.2479, -1.2654,  ..., -0.5126, -0.3725, -0.1800],\n",
      "          [-1.1779, -1.1779, -1.2479,  ..., -0.9503, -0.8452, -0.7402],\n",
      "          [-1.1954, -1.1779, -1.2304,  ..., -1.0903, -1.0728, -1.0028],\n",
      "          ...,\n",
      "          [-0.8627, -1.0728, -1.5105,  ..., -0.9328, -0.6176, -0.9678],\n",
      "          [ 0.1877, -0.0749, -0.1625,  ..., -1.1253, -0.5126, -1.7731],\n",
      "          [-0.7227, -1.1429, -0.3200,  ..., -0.8277, -1.0553, -2.0182]],\n",
      "\n",
      "         [[-0.9330, -0.9853, -1.0027,  ...,  0.0605,  0.2522,  0.4788],\n",
      "          [-0.8981, -0.9156, -0.9853,  ..., -0.5147, -0.3927, -0.2707],\n",
      "          [-0.9156, -0.8981, -0.9678,  ..., -0.7238, -0.7413, -0.6541],\n",
      "          ...,\n",
      "          [-0.7587, -0.9853, -1.4036,  ..., -0.8110, -0.4798, -0.8633],\n",
      "          [ 0.4091,  0.1476,  0.0779,  ..., -0.8284, -0.1487, -1.5081],\n",
      "          [-0.4798, -0.8981, -0.0790,  ..., -0.5321, -0.7413, -1.7870]]],\n",
      "\n",
      "\n",
      "        [[[ 0.4337,  0.4166,  0.4508,  ...,  0.2111,  0.1939,  0.2111],\n",
      "          [ 0.4679,  0.4679,  0.4851,  ...,  0.2282,  0.2282,  0.2453],\n",
      "          [ 0.4851,  0.5022,  0.5193,  ...,  0.2624,  0.2624,  0.2453],\n",
      "          ...,\n",
      "          [-0.7650, -1.2959, -1.3302,  ..., -0.5938, -1.2617, -1.8268],\n",
      "          [-1.0904, -1.7069, -1.4672,  ..., -0.5424, -1.7925, -2.1008],\n",
      "          [-1.6213, -1.6213, -1.8097,  ..., -1.0048, -2.0323, -2.1179]],\n",
      "\n",
      "         [[ 0.9930,  1.0105,  1.0280,  ...,  0.7654,  0.7479,  0.7479],\n",
      "          [ 1.0105,  1.0455,  1.0630,  ...,  0.8004,  0.7654,  0.7479],\n",
      "          [ 1.0280,  1.0455,  1.0630,  ...,  0.8179,  0.8004,  0.7654],\n",
      "          ...,\n",
      "          [-0.5826, -1.1604, -1.1954,  ..., -0.1099, -0.9503, -1.6856],\n",
      "          [-0.8803, -1.5630, -1.3004,  ..., -0.0749, -1.6331, -2.0182],\n",
      "          [-1.4580, -1.4580, -1.6856,  ..., -0.6877, -1.9482, -2.0357]],\n",
      "\n",
      "         [[ 1.7860,  1.7860,  1.7860,  ...,  1.5768,  1.5942,  1.5594],\n",
      "          [ 1.7860,  1.8034,  1.8034,  ...,  1.5942,  1.5942,  1.5768],\n",
      "          [ 1.8034,  1.8034,  1.8208,  ...,  1.5942,  1.5768,  1.5768],\n",
      "          ...,\n",
      "          [-0.2881, -0.9156, -0.9156,  ...,  0.3045, -0.6018, -1.4384],\n",
      "          [-0.5147, -1.2816, -1.0027,  ...,  0.3568, -1.3513, -1.7870],\n",
      "          [-1.1421, -1.1247, -1.4210,  ..., -0.3230, -1.6999, -1.8044]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 1.1358,  1.1187,  1.1529,  ...,  0.7419,  0.7419,  0.7591],\n",
      "          [ 1.1187,  1.1187,  1.1529,  ...,  0.7248,  0.7248,  0.7591],\n",
      "          [ 1.1187,  1.1187,  1.1358,  ...,  0.6906,  0.7248,  0.7591],\n",
      "          ...,\n",
      "          [-0.9705, -1.6384, -1.4672,  ..., -0.5938, -1.3130, -1.8782],\n",
      "          [-1.2103, -1.6384, -1.5014,  ..., -0.5424, -1.8097, -2.1008],\n",
      "          [-1.6384, -1.6042, -1.8268,  ..., -1.0219, -2.0323, -2.1179]],\n",
      "\n",
      "         [[ 1.5882,  1.5707,  1.5532,  ...,  0.8880,  0.8880,  0.8880],\n",
      "          [ 1.5882,  1.5707,  1.5707,  ...,  0.8704,  0.8704,  0.9055],\n",
      "          [ 1.5707,  1.5707,  1.5707,  ...,  0.8529,  0.8704,  0.9055],\n",
      "          ...,\n",
      "          [-0.8102, -1.5280, -1.3529,  ..., -0.1275, -1.0028, -1.7731],\n",
      "          [-1.0028, -1.4755, -1.3354,  ..., -0.0749, -1.6331, -2.0182],\n",
      "          [-1.4930, -1.4230, -1.7206,  ..., -0.7052, -1.9307, -2.0357]],\n",
      "\n",
      "         [[ 1.9254,  1.9080,  1.8905,  ...,  1.2457,  1.2457,  1.2108],\n",
      "          [ 1.8905,  1.8731,  1.8731,  ...,  1.2282,  1.2282,  1.2282],\n",
      "          [ 1.8557,  1.8557,  1.8905,  ...,  1.2108,  1.2282,  1.2631],\n",
      "          ...,\n",
      "          [-0.5147, -1.2816, -1.0724,  ...,  0.2871, -0.6715, -1.5081],\n",
      "          [-0.6541, -1.1944, -1.0201,  ...,  0.3568, -1.3687, -1.7870],\n",
      "          [-1.1770, -1.1073, -1.4384,  ..., -0.3404, -1.6999, -1.8044]]],\n",
      "\n",
      "\n",
      "        [[[ 0.7591,  0.7591,  0.7591,  ...,  0.6734,  0.6906,  0.6906],\n",
      "          [ 0.7591,  0.7591,  0.7591,  ...,  0.6734,  0.6734,  0.6734],\n",
      "          [ 0.7591,  0.7248,  0.7419,  ...,  0.6563,  0.6563,  0.6563],\n",
      "          ...,\n",
      "          [-0.7650, -1.0562, -1.3815,  ..., -0.5938, -1.3302, -1.9124],\n",
      "          [-1.0562, -1.8782, -1.4672,  ..., -0.5424, -1.8097, -2.1008],\n",
      "          [-1.2788, -1.3644, -1.5699,  ..., -1.0219, -2.0494, -2.1179]],\n",
      "\n",
      "         [[ 0.8354,  0.8529,  0.8354,  ...,  0.8179,  0.8179,  0.8179],\n",
      "          [ 0.8354,  0.8354,  0.8354,  ...,  0.8354,  0.8004,  0.8179],\n",
      "          [ 0.8354,  0.8179,  0.8179,  ...,  0.8179,  0.8004,  0.8004],\n",
      "          ...,\n",
      "          [-0.6001, -0.9153, -1.2654,  ..., -0.1275, -1.0203, -1.7906],\n",
      "          [-0.8452, -1.7556, -1.3179,  ..., -0.0749, -1.6506, -2.0357],\n",
      "          [-1.0553, -1.1429, -1.4230,  ..., -0.7052, -1.9482, -2.0357]],\n",
      "\n",
      "         [[ 1.0714,  1.0888,  1.0888,  ...,  1.0365,  1.0714,  1.0714],\n",
      "          [ 1.0714,  1.0714,  1.0888,  ...,  1.0365,  1.0539,  1.0714],\n",
      "          [ 1.0714,  1.0714,  1.0888,  ...,  1.0365,  1.0539,  1.0539],\n",
      "          ...,\n",
      "          [-0.3230, -0.6541, -0.9853,  ...,  0.3045, -0.6890, -1.5256],\n",
      "          [-0.5321, -1.5081, -1.0201,  ...,  0.3568, -1.3687, -1.7870],\n",
      "          [-0.7064, -0.8110, -1.1073,  ..., -0.3404, -1.6999, -1.8044]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3481,  0.3652,  0.3652,  ...,  0.4337,  0.4337,  0.4337],\n",
      "          [ 0.3309,  0.3481,  0.3481,  ...,  0.4337,  0.4166,  0.4166],\n",
      "          [ 0.3481,  0.3481,  0.3481,  ...,  0.4337,  0.4166,  0.4166],\n",
      "          ...,\n",
      "          [-0.8849, -1.4500, -1.4158,  ..., -0.5938, -1.1418, -1.7583],\n",
      "          [-1.2274, -1.6898, -1.4843,  ..., -0.5253, -1.7240, -2.1179],\n",
      "          [-1.6213, -1.5870, -1.8097,  ..., -0.9363, -1.9980, -2.1008]],\n",
      "\n",
      "         [[ 0.7304,  0.7479,  0.7304,  ...,  0.8704,  0.8704,  0.8704],\n",
      "          [ 0.7129,  0.7304,  0.7304,  ...,  0.8704,  0.8704,  0.8704],\n",
      "          [ 0.7129,  0.7304,  0.7129,  ...,  0.8704,  0.8704,  0.8704],\n",
      "          ...,\n",
      "          [-0.7402, -1.3354, -1.2829,  ..., -0.1275, -0.8102, -1.6155],\n",
      "          [-1.0203, -1.5280, -1.3179,  ..., -0.0399, -1.5455, -2.0182],\n",
      "          [-1.4580, -1.4230, -1.6856,  ..., -0.6001, -1.8957, -2.0357]],\n",
      "\n",
      "         [[ 1.1585,  1.1759,  1.1759,  ...,  1.2631,  1.2631,  1.2631],\n",
      "          [ 1.1759,  1.1759,  1.1759,  ...,  1.2631,  1.2631,  1.2631],\n",
      "          [ 1.1934,  1.1759,  1.1759,  ...,  1.2631,  1.2631,  1.2631],\n",
      "          ...,\n",
      "          [-0.4450, -1.0724, -1.0027,  ...,  0.2871, -0.4624, -1.3513],\n",
      "          [-0.7064, -1.2467, -1.0201,  ...,  0.3916, -1.2467, -1.7696],\n",
      "          [-1.1421, -1.1073, -1.4036,  ..., -0.2184, -1.6476, -1.8044]]]]), ('Embraer', 'Airbus', 'McDonnell', 'Cessna', 'British', 'Dornier', 'Cessna', 'Boeing', 'McDonnell', 'Airbus', 'Fokker', 'Saab', 'Boeing', 'British', 'Boeing', 'Boeing', 'Dassault', 'Canadair', 'Ilyushin', 'Boeing', 'Dassault', 'Fokker', 'Beechcraft', 'Tupolev', 'Dassault', 'Boeing', 'Boeing', 'Cessna', 'Lockheed', 'Boeing', 'Cessna', 'Antonov', 'Tupolev', 'Boeing', 'Boeing', 'Beechcraft', 'Bombardier', 'Eurofighter', 'Antonov', 'Airbus', 'Canadair', 'Boeing', 'de', 'Boeing', 'Fokker', 'Boeing', 'Fokker', 'McDonnell', 'British', 'Boeing', 'McDonnell', 'McDonnell', 'Lockheed', 'Boeing', 'Canadair', 'British', 'Boeing', 'Antonov', 'Boeing', 'Boeing', 'British', 'Boeing', 'Boeing', 'Bombardier')]\n"
     ]
    }
   ],
   "source": [
    "#перевіримо перший батч (виявилось, що забула додати енкодінг лейблів, \n",
    "#після цього було створено класс AircraftDatasetWithEncoding, продовжимо)\n",
    "first_batch = next(iter(train_data_loader))\n",
    "print(first_batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a4274133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1: epoch_loss: 2.8943128405876886\n",
      "epoch 2: epoch_loss: 2.9049740197523586\n",
      "epoch 3: epoch_loss: 2.903167756098621\n",
      "epoch 4: epoch_loss: 2.8941094650412498\n",
      "epoch 5: epoch_loss: 2.902301032588167\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 5 #спочатку тут було 50 епох, але вантажило занадто довго навіть до 10, тому будемо дивитись на 5\n",
    "n_iters = len(train_data_loader)\n",
    "n_tab = str(len(str(n_epochs)))\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    epoch_loss = 0 \n",
    "    \n",
    "    for current_batch in train_data_loader:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        X_batch, Y_batch = current_batch\n",
    "        X_batch = X_batch.to(device)\n",
    "        Y_batch = Y_batch.to(device)\n",
    "        \n",
    "        Y_pred = model(X_batch)\n",
    "        \n",
    "        loss = loss_function(Y_pred.squeeze(), torch.flatten(Y_batch))\n",
    "        step_loss_values.append(loss)\n",
    "\n",
    "        epoch_loss += loss.item() / n_iters\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    epoch_loss_values.append(epoch_loss)\n",
    "            \n",
    "    print(('epoch {:' + n_tab + '}: epoch_loss: {}').format(epoch+1, epoch_loss)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "6ea50374",
   "metadata": {},
   "outputs": [],
   "source": [
    "del step_loss_values\n",
    "del epoch_loss_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "22796bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#створюємо порожній масив numpy для зберігання прогнозованих міток тренувального набору даних\n",
    "Y_predicted_train = np.empty([0])\n",
    "\n",
    "#використовуємо контекст 'torch.no_grad()' для вимкнення розрахунку градієнтів під час прогнозування\n",
    "with torch.no_grad():\n",
    "    #ітеруємо по кожному пакету тренувального завантажувача даних\n",
    "    for current_batch in train_data_loader:\n",
    "        \n",
    "        #розділяємо дані та мітки поточного пакету\n",
    "        X_batch, Y_batch = current_batch\n",
    "        #конвертуємо дані в FloatTensor та переміщуємо на пристрій\n",
    "        X_batch = X_batch.type(torch.FloatTensor).to(device)\n",
    "        #переміщуємо мітки на  пристрій\n",
    "        Y_batch = Y_batch.to(device)\n",
    "\n",
    "        #виконуємо пряме поширення моделі для отримання вихідних даних на основі вхідного пакету\n",
    "        Y_pred = model(X_batch)\n",
    "        #застосовуємо softmax для перетворення вихідних значень моделі на ймовірності класів\n",
    "        Y_pred_norm = F.softmax(Y_pred, dim=1)\n",
    "        #отримуємо індекс класу з найвищою ймовірністю для кожного елементу в пакеті\n",
    "        Y_pred_label = Y_pred_norm.argmax(dim=1)\n",
    "        #конвертуємо прогнози в масив numpy та додаємо їх до загального масиву прогнозованих міток\n",
    "        Y_pred_label = Y_pred_label.detach().cpu().numpy()\n",
    "        Y_predicted_train = np.append(Y_predicted_train, Y_pred_label)\n",
    "        \n",
    "        #видаляємо використані змінні для звільнення пам'яті\n",
    "        del X_batch\n",
    "        del Y_batch\n",
    "        del Y_pred_label\n",
    "        #очищуємо кеш\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "#Y_predicted_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "167bb645",
   "metadata": {},
   "outputs": [],
   "source": [
    "#створюємо порожній масив numpy для зберігання прогнозованих міток тестового набору даних\n",
    "Y_predicted_test = np.empty([0])\n",
    "\n",
    "#використовуємо контекст 'torch.no_grad()' для вимкнення розрахунку градієнтів під час прогнозування\n",
    "with torch.no_grad():\n",
    "    #ітеруємо по кожному пакету тестового завантажувача даних\n",
    "    for current_batch in test_data_loader:\n",
    "        \n",
    "        #розділяємо дані та мітки поточного пакету\n",
    "        X_batch, Y_batch = current_batch\n",
    "        #конвертуємо дані в FloatTensor та переміщуємо на пристрій\n",
    "        X_batch = X_batch.type(torch.FloatTensor).to(device)\n",
    "        #переміщуємо мітки на пристрій\n",
    "        Y_batch = Y_batch.to(device)\n",
    "\n",
    "        #виконуємо пряме поширення моделі для отримання вихідних даних на основі вхідного пакету\n",
    "        Y_pred = model(X_batch)\n",
    "        #застосовуємо softmax для перетворення вихідних значень моделі на ймовірності класів\n",
    "        Y_pred_norm = F.softmax(Y_pred, dim=1)\n",
    "        #отримуємо індекс класу з найвищою ймовірністю для кожного елементу в пакеті\n",
    "        Y_pred_label = Y_pred_norm.argmax(dim=1)\n",
    "        #конвертуємо прогнози в масив numpy та додаємо їх до загального масиву прогнозованих міток\n",
    "        Y_pred_label = Y_pred_label.detach().cpu().numpy()\n",
    "        Y_predicted_test = np.append(Y_predicted_test, Y_pred_label)\n",
    "        \n",
    "        #видаляємо використані змінні для звільнення пам'яті\n",
    "        del X_batch\n",
    "        del Y_batch\n",
    "        del Y_pred_label\n",
    "        #очищуємо кеш\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "#Y_predicted_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "2468235f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#дістаємо лейбли\n",
    "Y_train_labels = [label for _, label in train_dataset]\n",
    "Y_test_labels = [label for _, label in test_dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "dbe109ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#переводимо лейбли в масив\n",
    "Y_train_labels = np.array(Y_train_labels)\n",
    "Y_test_labels = np.array(Y_test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "8548f95e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3334,), (3333,))"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_labels.shape, Y_test_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "6f4e1956",
   "metadata": {},
   "outputs": [],
   "source": [
    "#з файлц manufacturer.txt\n",
    "labels_map={\n",
    "    0: 'ATR',\n",
    "    1: 'Airbus',\n",
    "    2: 'Antonov',\n",
    "    3: 'Beechcraft',\n",
    "    4: 'Boeing',\n",
    "    5: 'Bombardier Aerospace',\n",
    "    6: 'British Aerospace',\n",
    "    7: 'Canadair',\n",
    "    8: 'Cessna',\n",
    "    9: 'Cirrus Aircraft',\n",
    "    10: 'Dassault Aviation',\n",
    "    11: 'Dornier',\n",
    "    12: 'Douglas Aircraft Company',\n",
    "    13: 'Embraer',\n",
    "    14: 'Eurofighter',\n",
    "    15: 'Fairchild',\n",
    "    16: 'Fokker',\n",
    "    17: 'Gulfstream Aerospace',\n",
    "    18: 'Ilyushin',\n",
    "    19: 'Lockheed Corporation',\n",
    "    20: 'Lockheed Martin',\n",
    "    21: 'McDonnell Douglas',\n",
    "    22: 'Panavia',\n",
    "    23: 'Piper',\n",
    "    24: 'Robin',\n",
    "    25: 'Saab',\n",
    "    26: 'Supermarine',\n",
    "    27: 'Tupolev',\n",
    "    28: 'Yakovlev',\n",
    "    29: 'de Havilland',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "1f91a9c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATR\n",
      "[[3268    0]\n",
      " [  66    0]]\n",
      "Airbus\n",
      "[[2900    0]\n",
      " [ 434    0]]\n",
      "Antonov\n",
      "[[3300    0]\n",
      " [  34    0]]\n",
      "Beechcraft\n",
      "[[3267    0]\n",
      " [  67    0]]\n",
      "Boeing\n",
      "[[   0 2601]\n",
      " [   0  733]]\n",
      "Bombardier Aerospace\n",
      "[[3301    0]\n",
      " [  33    0]]\n",
      "British Aerospace\n",
      "[[3201    0]\n",
      " [ 133    0]]\n",
      "Canadair\n",
      "[[3200    0]\n",
      " [ 134    0]]\n",
      "Cessna\n",
      "[[3201    0]\n",
      " [ 133    0]]\n",
      "Cirrus Aircraft\n",
      "[[3301    0]\n",
      " [  33    0]]\n",
      "Dassault Aviation\n",
      "[[3267    0]\n",
      " [  67    0]]\n",
      "Dornier\n",
      "[[3300    0]\n",
      " [  34    0]]\n",
      "Douglas Aircraft Company\n",
      "[[3201    0]\n",
      " [ 133    0]]\n",
      "Embraer\n",
      "[[3101    0]\n",
      " [ 233    0]]\n",
      "Eurofighter\n",
      "[[3301    0]\n",
      " [  33    0]]\n",
      "Fairchild\n",
      "[[3301    0]\n",
      " [  33    0]]\n",
      "Fokker\n",
      "[[3234    0]\n",
      " [ 100    0]]\n",
      "Gulfstream Aerospace\n",
      "[[3267    0]\n",
      " [  67    0]]\n",
      "Ilyushin\n",
      "[[3301    0]\n",
      " [  33    0]]\n",
      "Lockheed Corporation\n",
      "[[3266    0]\n",
      " [  68    0]]\n",
      "Lockheed Martin\n",
      "[[3300    0]\n",
      " [  34    0]]\n",
      "McDonnell Douglas\n",
      "[[3102    0]\n",
      " [ 232    0]]\n",
      "Panavia\n",
      "[[3300    0]\n",
      " [  34    0]]\n",
      "Piper\n",
      "[[3301    0]\n",
      " [  33    0]]\n",
      "Robin\n",
      "[[3301    0]\n",
      " [  33    0]]\n",
      "Saab\n",
      "[[3267    0]\n",
      " [  67    0]]\n",
      "Supermarine\n",
      "[[3301    0]\n",
      " [  33    0]]\n",
      "Tupolev\n",
      "[[3268    0]\n",
      " [  66    0]]\n",
      "Yakovlev\n",
      "[[3300    0]\n",
      " [  34    0]]\n",
      "de Havilland\n",
      "[[3167    0]\n",
      " [ 167    0]]\n"
     ]
    }
   ],
   "source": [
    "conf_matr_train = multilabel_confusion_matrix(\n",
    "    y_true=Y_train_labels.squeeze(), \n",
    "    y_pred=Y_predicted_train.astype(int)\n",
    ")\n",
    "\n",
    "for k, label in enumerate(labels_map.values()):\n",
    "    print(label)\n",
    "    print(conf_matr_train[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "8204fb3f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATR\n",
      "[[3266    0]\n",
      " [  67    0]]\n",
      "Airbus\n",
      "[[2900    0]\n",
      " [ 433    0]]\n",
      "Antonov\n",
      "[[3300    0]\n",
      " [  33    0]]\n",
      "Beechcraft\n",
      "[[3267    0]\n",
      " [  66    0]]\n",
      "Boeing\n",
      "[[   0 2599]\n",
      " [   0  734]]\n",
      "Bombardier Aerospace\n",
      "[[3300    0]\n",
      " [  33    0]]\n",
      "British Aerospace\n",
      "[[3200    0]\n",
      " [ 133    0]]\n",
      "Canadair\n",
      "[[3200    0]\n",
      " [ 133    0]]\n",
      "Cessna\n",
      "[[3199    0]\n",
      " [ 134    0]]\n",
      "Cirrus Aircraft\n",
      "[[3299    0]\n",
      " [  34    0]]\n",
      "Dassault Aviation\n",
      "[[3266    0]\n",
      " [  67    0]]\n",
      "Dornier\n",
      "[[3300    0]\n",
      " [  33    0]]\n",
      "Douglas Aircraft Company\n",
      "[[3200    0]\n",
      " [ 133    0]]\n",
      "Embraer\n",
      "[[3100    0]\n",
      " [ 233    0]]\n",
      "Eurofighter\n",
      "[[3299    0]\n",
      " [  34    0]]\n",
      "Fairchild\n",
      "[[3299    0]\n",
      " [  34    0]]\n",
      "Fokker\n",
      "[[3233    0]\n",
      " [ 100    0]]\n",
      "Gulfstream Aerospace\n",
      "[[3266    0]\n",
      " [  67    0]]\n",
      "Ilyushin\n",
      "[[3299    0]\n",
      " [  34    0]]\n",
      "Lockheed Corporation\n",
      "[[3267    0]\n",
      " [  66    0]]\n",
      "Lockheed Martin\n",
      "[[3300    0]\n",
      " [  33    0]]\n",
      "McDonnell Douglas\n",
      "[[3100    0]\n",
      " [ 233    0]]\n",
      "Panavia\n",
      "[[3300    0]\n",
      " [  33    0]]\n",
      "Piper\n",
      "[[3300    0]\n",
      " [  33    0]]\n",
      "Robin\n",
      "[[3299    0]\n",
      " [  34    0]]\n",
      "Saab\n",
      "[[3267    0]\n",
      " [  66    0]]\n",
      "Supermarine\n",
      "[[3299    0]\n",
      " [  34    0]]\n",
      "Tupolev\n",
      "[[3266    0]\n",
      " [  67    0]]\n",
      "Yakovlev\n",
      "[[3300    0]\n",
      " [  33    0]]\n",
      "de Havilland\n",
      "[[3167    0]\n",
      " [ 166    0]]\n"
     ]
    }
   ],
   "source": [
    "conf_matr_test = multilabel_confusion_matrix(\n",
    "    y_true=Y_test_labels.squeeze(), \n",
    "    y_pred=Y_predicted_test.astype(int)\n",
    ")\n",
    "\n",
    "for k, label in enumerate(labels_map.values()):\n",
    "    print(label)\n",
    "    print(conf_matr_test[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "79a5a21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#визначаємо функцію для створення великої матриці невідповідностей\n",
    "def large_confusion_matrix(y_true, y_pred, num_labels, norm=False):\n",
    "    #ініціалізуємо матрицю нулів\n",
    "    output_matrix = np.zeros([num_labels, num_labels]).astype(int)\n",
    "\n",
    "    #проходимо по кожному елементу в реальних та прогнозованих мітках\n",
    "    for j in range(len(y_true)):\n",
    "        #збільшуємо відповідну комірку в матриці\n",
    "        output_matrix[int(y_true[j]), int(y_pred[j])] += 1\n",
    "\n",
    "    if norm:\n",
    "        #конвертуємо матрицю в тип float для нормалізації\n",
    "        output_matrix = output_matrix.astype(float)\n",
    "\n",
    "        #проходимо по кожному рядку матриці\n",
    "        for j in range(num_labels):\n",
    "            #обчислюємо суму значень в рядку\n",
    "            row_sum = np.sum(output_matrix[j,])\n",
    "            #якщо сума більша за 0, то нормалізуємо рядок\n",
    "            if row_sum > 0:\n",
    "                output_matrix[j,] /= row_sum\n",
    "        output_matrix = np.round(output_matrix, 2)\n",
    "\n",
    "    return output_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "440f6b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = large_confusion_matrix(Y_test_labels, Y_predicted_test, 30, norm=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "55cc4bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfm_test = large_confusion_matrix(\n",
    "    y_true=Y_test_labels, \n",
    "    y_pred=Y_predicted_test.astype(int), \n",
    "    num_labels=30\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "927afc2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.22022202220222023\n"
     ]
    }
   ],
   "source": [
    "correct_predictions = np.sum(np.diag(cfm_test))\n",
    "\n",
    "total_test_samples = len(Y_test_labels) \n",
    "accuracy = correct_predictions / total_test_samples\n",
    "\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "92c698c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix_train = large_confusion_matrix(Y_train_labels, Y_predicted_train, 30, norm=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "754f95ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#використовуємо функцію large_confusion_matrix для створення матриці помилок на основі тренувальних даних\n",
    "cfm_train = large_confusion_matrix(\n",
    "    y_true=Y_train_labels,  #реальні мітки з тренувального набору даних\n",
    "    y_pred=Y_predicted_train.astype(int),  #прогнозовані мітки з тренувального набору даних\n",
    "    num_labels=30 \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "dfadc4bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.21985602879424115\n"
     ]
    }
   ],
   "source": [
    "#обчислюємо кількість правильних прогнозів\n",
    "#np.diag витягує діагональні елементи матриці (правильні прогнози)\n",
    "correct_predictions = np.sum(np.diag(cfm_train))\n",
    "\n",
    "#ділимо кількість правильних прогнозів на загальну кількість тренувальних зразків\n",
    "total_train_samples = len(Y_train_labels)  #загальна кількість тренувальних зразків\n",
    "accuracy = correct_predictions / total_train_samples\n",
    "\n",
    "# Друкуємо розраховану точність.\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "56847b00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.21985602879424115\n",
      "Test Accuracy: 0.22022202220222023\n",
      "No significant overfitting detected.\n"
     ]
    }
   ],
   "source": [
    "#функція для обчислення точності\n",
    "def calculate_accuracy(y_true, y_pred):\n",
    "    #розрахунок кількості правильних прогнозів\n",
    "    correct_predictions = np.sum(y_true == y_pred)\n",
    "    #визначення загальної кількості зразків\n",
    "    total_samples = len(y_true)\n",
    "    #повернення відношення правильних прогнозів до загальної кількості зразків\n",
    "    return correct_predictions / total_samples\n",
    "\n",
    "#розрахунок точності для навчального набору даних\n",
    "#припустимо, що Y_predicted_train та Y_train_labels доступні та мають відповідні форми\n",
    "train_accuracy = calculate_accuracy(Y_train_labels, Y_predicted_train.astype(int))\n",
    "\n",
    "#розрахунок точності для тестового набору даних\n",
    "#припустимо, що Y_predicted_test та Y_test_labels доступні та мають відповідні форми\n",
    "test_accuracy = calculate_accuracy(Y_test_labels, Y_predicted_test.astype(int))\n",
    "\n",
    "print(\"Training Accuracy:\", train_accuracy)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "#перевірка на перенавчання (overfitting)\n",
    "if train_accuracy > test_accuracy:\n",
    "    if train_accuracy - test_accuracy > 0.1:  \n",
    "        print(\"Potential overfitting detected.\")\n",
    "    else:\n",
    "        print(\"Slight difference in accuracies but might not be overfitting.\")\n",
    "else:\n",
    "    print(\"No significant overfitting detected.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f27d5c",
   "metadata": {},
   "source": [
    "Ситуація дуже погана, точність жахлива, але радує що однаково жахлива на обох датасетах, може коли буде краще,\n",
    "то стане однаково краще для обох.\n",
    "Додамо в нашу модель layer normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "712215e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdjustedCNN(SimpleCNN):\n",
    "    def __init__(self, num_classes):\n",
    "        super(AdjustedCNN, self).__init__(num_classes)\n",
    "        \n",
    "        #згорткові шари\n",
    "        self.features = nn.Sequential(\n",
    "            #перший згортковий шар з 64 фільтрами, розмір ядра 11x11\n",
    "            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            #нормалізація шару після ReLU\n",
    "            nn.LayerNorm([64, 55, 55]),   \n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            \n",
    "            #другий згортковий шар з 192 фільтрами, розмір ядра 5x5\n",
    "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            #нормалізація шару\n",
    "            nn.LayerNorm([192, 27, 27]),  \n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            \n",
    "            #третій згортковий шар з 384 фільтрами, розмір ядра 3x3\n",
    "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            #нормалізація шару\n",
    "            nn.LayerNorm([384, 13, 13]),  \n",
    "            \n",
    "            #четвертий згортковий шар з 256 фільтрами\n",
    "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            #нормалізація шару\n",
    "            nn.LayerNorm([256, 13, 13]),  \n",
    "            \n",
    "            #п’ятий згортковий шар з 256 фільтрами\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            #нормалізація шару\n",
    "            nn.LayerNorm([256, 13, 13]),  \n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "        )\n",
    "        \n",
    "        #пулінг\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
    "        \n",
    "        #класифікація\n",
    "        self.classifier = nn.Sequential(\n",
    "            #Dropout для зниження перенавчання\n",
    "            nn.Dropout(),  \n",
    "            #лінійний шар\n",
    "            nn.Linear(256 * 6 * 6, 4096),  \n",
    "             #функція активації.\n",
    "            nn.ReLU(inplace=True), \n",
    "            #ще один шар Dropout для регуляризації\n",
    "            nn.Dropout(),  \n",
    "            nn.Linear(4096, 4096), \n",
    "            nn.ReLU(inplace=True),\n",
    "            #останній шар з виходами num_classes\n",
    "            nn.Linear(4096, num_classes),  \n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        #прохід через згорткові шари\n",
    "        x = self.features(x) \n",
    "        #пулінг\n",
    "        x = self.avgpool(x)  \n",
    "        #вирівнювання виходу для лінійних шарів\n",
    "        x = torch.flatten(x, 1)  \n",
    "        #прохід через повністю з'єднані шари\n",
    "        x = self.classifier(x)  \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "ba185965",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 30  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "a3847a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AdjustedCNN(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "1a021fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_loss_values = []\n",
    "step_loss_values = []\n",
    "#функція втрат\n",
    "loss_function = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "5571281c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#спробуємо тепер використати RMSprop оптимізатор замість Адама\n",
    "optimizer = torch.optim.RMSprop(adjusted_cnn.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "743a5a6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1: epoch_loss: 3.3716372768833955\n",
      "epoch 2: epoch_loss: 3.368753797603104\n",
      "epoch 3: epoch_loss: 3.3779089180928357\n",
      "epoch 4: epoch_loss: 3.3717273901093674\n",
      "epoch 5: epoch_loss: 3.364855464899315\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 5 #спочатку тут було 50 епох, але вантажило занадто довго навіть до 10, тому будемо дивитись на 5\n",
    "n_iters = len(train_data_loader)\n",
    "n_tab = str(len(str(n_epochs)))\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    epoch_loss = 0 \n",
    "    \n",
    "    for current_batch in train_data_loader:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        X_batch, Y_batch = current_batch\n",
    "        X_batch = X_batch.to(device)\n",
    "        Y_batch = Y_batch.to(device)\n",
    "        \n",
    "        Y_pred = model(X_batch)\n",
    "        \n",
    "        loss = loss_function(Y_pred.squeeze(), torch.flatten(Y_batch))\n",
    "        step_loss_values.append(loss)\n",
    "\n",
    "        epoch_loss += loss.item() / n_iters\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    epoch_loss_values.append(epoch_loss)\n",
    "            \n",
    "    print(('epoch {:' + n_tab + '}: epoch_loss: {}').format(epoch+1, epoch_loss)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "804194cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "del step_loss_values\n",
    "del epoch_loss_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "071814a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#створюємо порожній масив numpy для зберігання прогнозованих міток тренувального набору даних\n",
    "Y_predicted_train = np.empty([0])\n",
    "\n",
    "#використовуємо контекст 'torch.no_grad()' для вимкнення розрахунку градієнтів під час прогнозування\n",
    "with torch.no_grad():\n",
    "    #ітеруємо по кожному пакету тренувального завантажувача даних\n",
    "    for current_batch in train_data_loader:\n",
    "        \n",
    "        #розділяємо дані та мітки поточного пакету\n",
    "        X_batch, Y_batch = current_batch\n",
    "        #конвертуємо дані в FloatTensor та переміщуємо на пристрій\n",
    "        X_batch = X_batch.type(torch.FloatTensor).to(device)\n",
    "        #переміщуємо мітки на  пристрій\n",
    "        Y_batch = Y_batch.to(device)\n",
    "\n",
    "        #виконуємо пряме поширення моделі для отримання вихідних даних на основі вхідного пакету\n",
    "        Y_pred = model(X_batch)\n",
    "        #застосовуємо softmax для перетворення вихідних значень моделі на ймовірності класів\n",
    "        Y_pred_norm = F.softmax(Y_pred, dim=1)\n",
    "        #отримуємо індекс класу з найвищою ймовірністю для кожного елементу в пакеті\n",
    "        Y_pred_label = Y_pred_norm.argmax(dim=1)\n",
    "        #конвертуємо прогнози в масив numpy та додаємо їх до загального масиву прогнозованих міток\n",
    "        Y_pred_label = Y_pred_label.detach().cpu().numpy()\n",
    "        Y_predicted_train = np.append(Y_predicted_train, Y_pred_label)\n",
    "        \n",
    "        #видаляємо використані змінні для звільнення пам'яті\n",
    "        del X_batch\n",
    "        del Y_batch\n",
    "        del Y_pred_label\n",
    "        #очищуємо кеш\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "#Y_predicted_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "d36345bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#створюємо порожній масив numpy для зберігання прогнозованих міток тестового набору даних\n",
    "Y_predicted_test = np.empty([0])\n",
    "\n",
    "#використовуємо контекст 'torch.no_grad()' для вимкнення розрахунку градієнтів під час прогнозування\n",
    "with torch.no_grad():\n",
    "    #ітеруємо по кожному пакету тестового завантажувача даних\n",
    "    for current_batch in test_data_loader:\n",
    "        \n",
    "        #розділяємо дані та мітки поточного пакету\n",
    "        X_batch, Y_batch = current_batch\n",
    "        #конвертуємо дані в FloatTensor та переміщуємо на пристрій\n",
    "        X_batch = X_batch.type(torch.FloatTensor).to(device)\n",
    "        #переміщуємо мітки на пристрій\n",
    "        Y_batch = Y_batch.to(device)\n",
    "\n",
    "        #виконуємо пряме поширення моделі для отримання вихідних даних на основі вхідного пакету\n",
    "        Y_pred = model(X_batch)\n",
    "        #застосовуємо softmax для перетворення вихідних значень моделі на ймовірності класів\n",
    "        Y_pred_norm = F.softmax(Y_pred, dim=1)\n",
    "        #отримуємо індекс класу з найвищою ймовірністю для кожного елементу в пакеті\n",
    "        Y_pred_label = Y_pred_norm.argmax(dim=1)\n",
    "        #конвертуємо прогнози в масив numpy та додаємо їх до загального масиву прогнозованих міток\n",
    "        Y_pred_label = Y_pred_label.detach().cpu().numpy()\n",
    "        Y_predicted_test = np.append(Y_predicted_test, Y_pred_label)\n",
    "        \n",
    "        #видаляємо використані змінні для звільнення пам'яті\n",
    "        del X_batch\n",
    "        del Y_batch\n",
    "        del Y_pred_label\n",
    "        #очищуємо кеш\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "#Y_predicted_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "90bcc546",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATR\n",
      "[[3243   25]\n",
      " [  64    2]]\n",
      "Airbus\n",
      "[[2719  181]\n",
      " [ 408   26]]\n",
      "Antonov\n",
      "[[3300    0]\n",
      " [  34    0]]\n",
      "Beechcraft\n",
      "[[3261    6]\n",
      " [  67    0]]\n",
      "Boeing\n",
      "[[2482  119]\n",
      " [ 703   30]]\n",
      "Bombardier Aerospace\n",
      "[[3295    6]\n",
      " [  33    0]]\n",
      "British Aerospace\n",
      "[[2933  268]\n",
      " [ 121   12]]\n",
      "Canadair\n",
      "[[2987  213]\n",
      " [ 129    5]]\n",
      "Cessna\n",
      "[[3201    0]\n",
      " [ 133    0]]\n",
      "Cirrus Aircraft\n",
      "[[2914  387]\n",
      " [  33    0]]\n",
      "Dassault Aviation\n",
      "[[3203   64]\n",
      " [  66    1]]\n",
      "Dornier\n",
      "[[3298    2]\n",
      " [  34    0]]\n",
      "Douglas Aircraft Company\n",
      "[[3102   99]\n",
      " [ 131    2]]\n",
      "Embraer\n",
      "[[2738  363]\n",
      " [ 215   18]]\n",
      "Eurofighter\n",
      "[[3059  242]\n",
      " [  31    2]]\n",
      "Fairchild\n",
      "[[3200  101]\n",
      " [  31    2]]\n",
      "Fokker\n",
      "[[2941  293]\n",
      " [  87   13]]\n",
      "Gulfstream Aerospace\n",
      "[[3146  121]\n",
      " [  62    5]]\n",
      "Ilyushin\n",
      "[[3297    4]\n",
      " [  33    0]]\n",
      "Lockheed Corporation\n",
      "[[3266    0]\n",
      " [  68    0]]\n",
      "Lockheed Martin\n",
      "[[3154  146]\n",
      " [  31    3]]\n",
      "McDonnell Douglas\n",
      "[[3082   20]\n",
      " [ 230    2]]\n",
      "Panavia\n",
      "[[3287   13]\n",
      " [  34    0]]\n",
      "Piper\n",
      "[[3180  121]\n",
      " [  31    2]]\n",
      "Robin\n",
      "[[3213   88]\n",
      " [  29    4]]\n",
      "Saab\n",
      "[[3009  258]\n",
      " [  63    4]]\n",
      "Supermarine\n",
      "[[3286   15]\n",
      " [  33    0]]\n",
      "Tupolev\n",
      "[[3264    4]\n",
      " [  66    0]]\n",
      "Yakovlev\n",
      "[[3300    0]\n",
      " [  34    0]]\n",
      "de Havilland\n",
      "[[3127   40]\n",
      " [ 165    2]]\n"
     ]
    }
   ],
   "source": [
    "conf_matr_train = multilabel_confusion_matrix(\n",
    "    y_true=Y_train_labels.squeeze(), \n",
    "    y_pred=Y_predicted_train.astype(int)\n",
    ")\n",
    "\n",
    "for k, label in enumerate(labels_map.values()):\n",
    "    print(label)\n",
    "    print(conf_matr_train[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "1e15cd5f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATR\n",
      "[[3248   18]\n",
      " [  66    1]]\n",
      "Airbus\n",
      "[[2712  188]\n",
      " [ 408   25]]\n",
      "Antonov\n",
      "[[3295    5]\n",
      " [  33    0]]\n",
      "Beechcraft\n",
      "[[3254   13]\n",
      " [  66    0]]\n",
      "Boeing\n",
      "[[2483  116]\n",
      " [ 701   33]]\n",
      "Bombardier Aerospace\n",
      "[[3294    6]\n",
      " [  33    0]]\n",
      "British Aerospace\n",
      "[[2923  277]\n",
      " [ 117   16]]\n",
      "Canadair\n",
      "[[3016  184]\n",
      " [ 126    7]]\n",
      "Cessna\n",
      "[[3198    1]\n",
      " [ 134    0]]\n",
      "Cirrus Aircraft\n",
      "[[2901  398]\n",
      " [  32    2]]\n",
      "Dassault Aviation\n",
      "[[3202   64]\n",
      " [  66    1]]\n",
      "Dornier\n",
      "[[3295    5]\n",
      " [  33    0]]\n",
      "Douglas Aircraft Company\n",
      "[[3104   96]\n",
      " [ 128    5]]\n",
      "Embraer\n",
      "[[2744  356]\n",
      " [ 203   30]]\n",
      "Eurofighter\n",
      "[[3054  245]\n",
      " [  31    3]]\n",
      "Fairchild\n",
      "[[3205   94]\n",
      " [  34    0]]\n",
      "Fokker\n",
      "[[2929  304]\n",
      " [  91    9]]\n",
      "Gulfstream Aerospace\n",
      "[[3124  142]\n",
      " [  63    4]]\n",
      "Ilyushin\n",
      "[[3296    3]\n",
      " [  34    0]]\n",
      "Lockheed Corporation\n",
      "[[3267    0]\n",
      " [  66    0]]\n",
      "Lockheed Martin\n",
      "[[3170  130]\n",
      " [  31    2]]\n",
      "McDonnell Douglas\n",
      "[[3082   18]\n",
      " [ 231    2]]\n",
      "Panavia\n",
      "[[3288   12]\n",
      " [  33    0]]\n",
      "Piper\n",
      "[[3163  137]\n",
      " [  31    2]]\n",
      "Robin\n",
      "[[3205   94]\n",
      " [  34    0]]\n",
      "Saab\n",
      "[[3040  227]\n",
      " [  61    5]]\n",
      "Supermarine\n",
      "[[3288   11]\n",
      " [  34    0]]\n",
      "Tupolev\n",
      "[[3261    5]\n",
      " [  66    1]]\n",
      "Yakovlev\n",
      "[[3300    0]\n",
      " [  33    0]]\n",
      "de Havilland\n",
      "[[3134   33]\n",
      " [ 163    3]]\n"
     ]
    }
   ],
   "source": [
    "conf_matr_test = multilabel_confusion_matrix(\n",
    "    y_true=Y_test_labels.squeeze(), \n",
    "    y_pred=Y_predicted_test.astype(int)\n",
    ")\n",
    "\n",
    "for k, label in enumerate(labels_map.values()):\n",
    "    print(label)\n",
    "    print(conf_matr_test[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "31f29ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = large_confusion_matrix(Y_test_labels, Y_predicted_test, 30, norm=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "6a2bafbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.045304530453045305\n"
     ]
    }
   ],
   "source": [
    "cfm_test = large_confusion_matrix(\n",
    "    y_true=Y_test_labels, \n",
    "    y_pred=Y_predicted_test.astype(int), \n",
    "    num_labels=30\n",
    ")\n",
    "correct_predictions = np.sum(np.diag(cfm_test))\n",
    "\n",
    "total_test_samples = len(Y_test_labels) \n",
    "accuracy = correct_predictions / total_test_samples\n",
    "\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "fd08afae",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix_train = large_confusion_matrix(Y_train_labels, Y_predicted_train, 30, norm=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "32daa8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#використовуємо функцію large_confusion_matrix для створення матриці помилок на основі тренувальних даних\n",
    "cfm_train = large_confusion_matrix(\n",
    "    y_true=Y_train_labels,  #реальні мітки з тренувального набору даних\n",
    "    y_pred=Y_predicted_train.astype(int),  #прогнозовані мітки з тренувального набору даних\n",
    "    num_labels=30 \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "05631a7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.040491901619676064\n"
     ]
    }
   ],
   "source": [
    "#обчислюємо кількість правильних прогнозів\n",
    "#np.diag витягує діагональні елементи матриці (правильні прогнози)\n",
    "correct_predictions = np.sum(np.diag(cfm_train))\n",
    "\n",
    "#ділимо кількість правильних прогнозів на загальну кількість тренувальних зразків\n",
    "total_train_samples = len(Y_train_labels)  #загальна кількість тренувальних зразків\n",
    "accuracy = correct_predictions / total_train_samples\n",
    "\n",
    "# Друкуємо розраховану точність.\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "6b113bc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.040491901619676064\n",
      "Test Accuracy: 0.045304530453045305\n",
      "No significant overfitting detected.\n"
     ]
    }
   ],
   "source": [
    "#функція для обчислення точності\n",
    "def calculate_accuracy(y_true, y_pred):\n",
    "    #розрахунок кількості правильних прогнозів\n",
    "    correct_predictions = np.sum(y_true == y_pred)\n",
    "    #визначення загальної кількості зразків\n",
    "    total_samples = len(y_true)\n",
    "    #повернення відношення правильних прогнозів до загальної кількості зразків\n",
    "    return correct_predictions / total_samples\n",
    "\n",
    "#розрахунок точності для навчального набору даних\n",
    "#припустимо, що Y_predicted_train та Y_train_labels доступні та мають відповідні форми\n",
    "train_accuracy = calculate_accuracy(Y_train_labels, Y_predicted_train.astype(int))\n",
    "\n",
    "#розрахунок точності для тестового набору даних\n",
    "#припустимо, що Y_predicted_test та Y_test_labels доступні та мають відповідні форми\n",
    "test_accuracy = calculate_accuracy(Y_test_labels, Y_predicted_test.astype(int))\n",
    "\n",
    "print(\"Training Accuracy:\", train_accuracy)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "#перевірка на перенавчання (overfitting)\n",
    "if train_accuracy > test_accuracy:\n",
    "    if train_accuracy - test_accuracy > 0.1:  \n",
    "        print(\"Potential overfitting detected.\")\n",
    "    else:\n",
    "        print(\"Slight difference in accuracies but might not be overfitting.\")\n",
    "else:\n",
    "    print(\"No significant overfitting detected.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a630b70",
   "metadata": {},
   "source": [
    "Стало ще гірше, скоріш дуже мало епох було при тренуванні, мережі просто по суті не встигли навчитись.\n",
    "Але 5 епох ватнажило 40 хвилин для першої CNN, може можна було б бачити краще картину при довшому тренуванні.\n",
    "Спробуємо поглянути на VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "d9db952c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomVGG16(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CustomVGG16, self).__init__()\n",
    "        #завантажимо модель\n",
    "        self.vgg16 = models.vgg16(pretrained=True)\n",
    "        #змінимо кількість класів на потрібну під наші дані\n",
    "        num_features = self.vgg16.classifier[6].in_features\n",
    "        self.vgg16.classifier[6] = nn.Linear(num_features, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.vgg16(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "28f99890",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 30 \n",
    "model = CustomVGG16(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "57a9ee03",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_loss_values = []\n",
    "step_loss_values = []\n",
    "#функція втрат\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "#оптимізатор Адам\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "32b2d155",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[152], line 23\u001b[0m\n\u001b[1;32m     19\u001b[0m     step_loss_values\u001b[38;5;241m.\u001b[39mappend(loss)\n\u001b[1;32m     21\u001b[0m     epoch_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m/\u001b[39m n_iters\n\u001b[0;32m---> 23\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     26\u001b[0m epoch_loss_values\u001b[38;5;241m.\u001b[39mappend(epoch_loss)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_epochs = 2 #спочатку тут було 50 епох, але вантажило занадто довго навіть до 10, тому будемо дивитись на 5\n",
    "n_iters = len(train_data_loader)\n",
    "n_tab = str(len(str(n_epochs)))\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    epoch_loss = 0 \n",
    "    \n",
    "    for current_batch in train_data_loader:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        X_batch, Y_batch = current_batch\n",
    "        X_batch = X_batch.to(device)\n",
    "        Y_batch = Y_batch.to(device)\n",
    "        \n",
    "        Y_pred = model(X_batch)\n",
    "        \n",
    "        loss = loss_function(Y_pred.squeeze(), torch.flatten(Y_batch))\n",
    "        step_loss_values.append(loss)\n",
    "\n",
    "        epoch_loss += loss.item() / n_iters\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    epoch_loss_values.append(epoch_loss)\n",
    "            \n",
    "    print(('epoch {:' + n_tab + '}: epoch_loss: {}').format(epoch+1, epoch_loss)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e950236",
   "metadata": {},
   "outputs": [],
   "source": [
    "del step_loss_values\n",
    "del epoch_loss_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e17b06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#функція для обчислення точності\n",
    "def calculate_accuracy(y_true, y_pred):\n",
    "    #розрахунок кількості правильних прогнозів\n",
    "    correct_predictions = np.sum(y_true == y_pred)\n",
    "    #визначення загальної кількості зразків\n",
    "    total_samples = len(y_true)\n",
    "    #повернення відношення правильних прогнозів до загальної кількості зразків\n",
    "    return correct_predictions / total_samples\n",
    "\n",
    "#розрахунок точності для навчального набору даних\n",
    "#припустимо, що Y_predicted_train та Y_train_labels доступні та мають відповідні форми\n",
    "train_accuracy = calculate_accuracy(Y_train_labels, Y_predicted_train.astype(int))\n",
    "\n",
    "#розрахунок точності для тестового набору даних\n",
    "#припустимо, що Y_predicted_test та Y_test_labels доступні та мають відповідні форми\n",
    "test_accuracy = calculate_accuracy(Y_test_labels, Y_predicted_test.astype(int))\n",
    "\n",
    "print(\"Training Accuracy:\", train_accuracy)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "#перевірка на перенавчання (overfitting)\n",
    "if train_accuracy > test_accuracy:\n",
    "    if train_accuracy - test_accuracy > 0.1:  \n",
    "        print(\"Potential overfitting detected.\")\n",
    "    else:\n",
    "        print(\"Slight difference in accuracies but might not be overfitting.\")\n",
    "else:\n",
    "    print(\"No significant overfitting detected.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab59a00",
   "metadata": {},
   "source": [
    "## Висновок\n",
    "\n",
    "Проблему з точністю моїх моделей CNN та Adjusted CNN можна спробувати виправити збільшенням кількості епох\n",
    "та також можна було поєднати тренувальну та валідаційну семпли та тренувати на цьому поєднанні, але ця думка дійшла до мене на середині тренування Adjusted CNN. \n",
    "\n",
    "Стосовно VGG16.\n",
    "VGG16 набагато довше тренувалась (на 5 епохах), змогло видати результат лише перших 2х епох:\n",
    "#### epoch 1: epoch_loss: 3564.683019480615\n",
    "#### epoch 2: epoch_loss: 4.1804626122960515\n",
    "\n",
    "потім kernel почав видавати таймаут.\n",
    "На 2х епохах вже почав лагати джупайтер та сам компʼютер, прийшлось зупинити (теж вийшло не з першої спроби).\n",
    "\n",
    "Тенденції втрат: Adjusted CNN і Custom VGG16 показують вищі втрати, ніж Simple CNN, що зазвичай вказує на нижчу продуктивність, але треба зазначити, що величезне значення втрат для першої епохи може бути індикатором проблеми у підготовці даних для моделі або некоректне обрання learning rate, або також у VGG16 велике перенавчання.\n",
    "\n",
    "Отже, на мою думку VGG16 краще використати у більш складних задачах (де, наприклад, набагато більше класів), бо там це буде зручніше, ніж намагатись\n",
    "налаштувати свою особисту мережу та робити свою архітектуру.\n",
    "\n",
    "Але на задачах більш легких краще її не використовувати, бо своя модель тренується швидше, надаючи приблизно такі ж самі результати.\n",
    "\n",
    "На складних задачах (навіть якщо тренування VGG16 займе багато часу) усе одно буде зекономлено час.\n",
    "Для більш простих задач це буде нелогічно, легше \"покрутити\" свою модель, швидше знайдеться помилка та вдосконалення."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a053eaaf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
